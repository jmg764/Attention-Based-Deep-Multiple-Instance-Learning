{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "infer_pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVG5nrRlFAkR"
      },
      "source": [
        "## SageMaker endpoint\n",
        "To deploy the model you previously trained, you need to create a Sagemaker Endpoint. This is a hosted prediction service that you can use to perform inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbFVlkdCE6xi"
      },
      "source": [
        "### Finding the model\n",
        "This notebook uses a stored model if it exists. If you recently ran a training example that use the %store% magic, it will be restored in the next cell.\n",
        "\n",
        "Otherwise, you can pass the URI to the model file (a .tar.gz file) in the model_data variable.\n",
        "\n",
        "You can find your model files through the SageMaker console by choosing Training > Training jobs in the left navigation pane. Find your recent training job, choose it, and then look for the s3:// link in the Output pane. Uncomment the model_data line in the next cell that manually sets the model's URI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArIXc850D18u"
      },
      "source": [
        "# Retrieve a saved model from a previous notebook run's stored variable\n",
        "%store -r model_data\n",
        "\n",
        "# If no model was found, set it manually here.\n",
        "# model_data = 's3://sagemaker-us-west-2-XXX/pytorch-smdataparallel-mnist-2020-10-16-17-15-16-419/output/model.tar.gz'\n",
        "\n",
        "print(\"Using this model: {}\".format(model_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDJ6ENagFNu-"
      },
      "source": [
        "### Create a model object\n",
        "You define the model object by using SageMaker SDK's PyTorchModel and pass in the model from the estimator and the entry_point. The endpoint's entry point for inference is defined by model_fn as seen in the following code block that prints out inference.py. The function loads the model and sets it to use a GPU, if available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox9u5cCVEHCH"
      },
      "source": [
        "!pygmentize inference.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrBb96KOEKT0"
      },
      "source": [
        "import sagemaker\n",
        "role = sagemaker.get_execution_role()\n",
        "\n",
        "from sagemaker.pytorch import PyTorchModel\n",
        "model = PyTorchModel(model_data=model_data,\n",
        "                        entry_point='inference.py', role=role, framework_version='1.6.0', py_version='py3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u6HzY_lFTBv"
      },
      "source": [
        "#### Deploy the model on an endpoint\n",
        "You create a predictor by using the model.deploy function. You can optionally change both the instance count and instance type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmSumXLREaMV"
      },
      "source": [
        "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOn7-dTgFW58"
      },
      "source": [
        "### Test the model\n",
        "You can test the depolyed model using samples from the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRjZBmrCFdfk"
      },
      "source": [
        "\n",
        "# Download the test set\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from train import TileDataset\n",
        "\n",
        "import boto3\n",
        "import pandas as pd\n",
        "from sagemaker import get_execution_role\n",
        "\n",
        "role = get_execution_role()\n",
        "bucket='sagemaker-us-east-2-318322629142'\n",
        "\n",
        "tiles_key = 'train_tiles/train_tiles/train_tiles/train_tiles/train_tiles/train_tiles/train_tiles/train_tiles/train_tiles/train_tiles/train_tiles/train_tiles/train_tiles/train_tiles/train_tiles/train_tiles/train_tiles/train_tiles/train_tiles/train_tiles/'\n",
        "tiles_dir = 's3://{}/{}'.format(bucket, tiles_key)\n",
        "\n",
        "# dataset_csv_key = ‘panda_dataset.csv’\n",
        "# dataset_csv_dir = 's3://{}/{}'.format(bucket, dataset_csv_key)\n",
        "\n",
        "# df = pd.read_csv(dataset_csv_dir)\n",
        "# df['isup_grade'] = df['isup_grade'].replace([1,2], 0)\n",
        "# df['isup_grade'] = df['isup_grade'].replace([3,4,5], 1)\n",
        "\n",
        "# tiles_dict = {}\n",
        "# for image in os.listdir(tiles_dir):\n",
        "#     tiles_dict[image.split('_')[0]] = tiles_dict.get(image.split('_')[0], 0) + 1\n",
        "\n",
        "# tiles_df = list(tiles_dict.keys())\n",
        "\n",
        "# new_tiles_df = []\n",
        "# for i in range(len(tiles_df)):\n",
        "#   row = df.loc[df['image_id'] == tiles_df[i]]\n",
        "#   new_tiles_df.append(row.to_dict())\n",
        "\n",
        "# tiles_df = pd.DataFrame(new_tiles_df)\n",
        "\n",
        "# # Use only half of the data\n",
        "# tiles_df = np.array_split(df, 2)\n",
        "\n",
        "# # Train-test split\n",
        "# train_df, test_df = train_test_split(tiles_df[0], test_size=0.2)\n",
        "\n",
        "test_df = pd.read_csv('s3://{}/{}'.format(bucket, 'test_df'))\n",
        "\n",
        "transform_train = transforms.Compose([transforms.RandomHorizontalFlip(0.5),\n",
        "                                      transforms.RandomVerticalFlip(0.5),\n",
        "                                      transforms.ToTensor()])\n",
        "\n",
        "test_set = TileDataset(tiles_dir, test_df, 12, transform=transform_train)\n",
        "\n",
        "batch_size = 1\n",
        "test_loader = data_utils.DataLoader(test_set, batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "# data, bag_label = iter(test_loader).next()\n",
        "# if cuda:\n",
        "#   data, bag_label = data.cuda(), bag_label.cuda()\n",
        "# data, bag_label = Variable(data), Variable(bag_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA5jhMK6FeRX"
      },
      "source": [
        "# Send the sampled images to endpoint for inference\n",
        "# error, predicted = predictor.calculate_classification_error(data, bag_label)\n",
        "predictions = []\n",
        "true_labels = []\n",
        "for batch_idx, (data, label) in enumerate(test_loader):\n",
        "  _, Y_hat, _ = predictor.predict(data)\n",
        "  predictions.append(int(Y_hat))\n",
        "  true_labels.append(label)\n",
        "\n",
        "\n",
        "# print(\"Predictions: \")\n",
        "# print(predicted.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqoA8ZlXFgqW"
      },
      "source": [
        "#### Cleanup\n",
        "If you don't intend on trying out inference or to do anything else with the endpoint, you should delete it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY8U_J9HFiNy"
      },
      "source": [
        "predictor.delete_endpoint()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}