{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVG5nrRlFAkR"
   },
   "source": [
    "## SageMaker endpoint\n",
    "To deploy the model you previously trained, you need to create a Sagemaker Endpoint. This is a hosted prediction service that you can use to perform inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbFVlkdCE6xi"
   },
   "source": [
    "### Finding the model\n",
    "This notebook uses a stored model if it exists. If you recently ran a training example that use the %store% magic, it will be restored in the next cell.\n",
    "\n",
    "Otherwise, you can pass the URI to the model file (a .tar.gz file) in the model_data variable.\n",
    "\n",
    "You can find your model files through the SageMaker console by choosing Training > Training jobs in the left navigation pane. Find your recent training job, choose it, and then look for the s3:// link in the Output pane. Uncomment the model_data line in the next cell that manually sets the model's URI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "ArIXc850D18u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable or alias model_data\n",
      "Using this model: s3://sagemaker-us-east-1-318322629142/pytorch-smdataparallel-histopathology-m-2021-05-18-18-59-25-802/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve a saved model from a previous notebook run's stored variable\n",
    "%store -r model_data\n",
    "\n",
    "# If no model was found, set it manually here.\n",
    "model_data = 's3://sagemaker-us-east-1-318322629142/pytorch-smdataparallel-histopathology-m-2021-05-18-18-59-25-802/output/model.tar.gz'\n",
    "\n",
    "print(\"Using this model: {}\".format(model_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDJ6ENagFNu-"
   },
   "source": [
    "### Create a model object\n",
    "You define the model object by using SageMaker SDK's PyTorchModel and pass in the model from the estimator and the entry_point. The endpoint's entry point for inference is defined by model_fn as seen in the following code block that prints out inference.py. The function loads the model and sets it to use a GPU, if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "ox9u5cCVEHCH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Licensed to the Apache Software Foundation (ASF) under one\u001b[39;49;00m\r\n",
      "\u001b[37m# or more contributor license agreements.  See the NOTICE file\u001b[39;49;00m\r\n",
      "\u001b[37m# distributed with this work for additional information\u001b[39;49;00m\r\n",
      "\u001b[37m# regarding copyright ownership.  The ASF licenses this file\u001b[39;49;00m\r\n",
      "\u001b[37m# to you under the Apache License, Version 2.0 (the\u001b[39;49;00m\r\n",
      "\u001b[37m# \"License\"); you may not use this file except in compliance\u001b[39;49;00m\r\n",
      "\u001b[37m# with the License.  You may obtain a copy of the License at\u001b[39;49;00m\r\n",
      "\u001b[37m#\u001b[39;49;00m\r\n",
      "\u001b[37m#   http://www.apache.org/licenses/LICENSE-2.0\u001b[39;49;00m\r\n",
      "\u001b[37m#\u001b[39;49;00m\r\n",
      "\u001b[37m# Unless required by applicable law or agreed to in writing,\u001b[39;49;00m\r\n",
      "\u001b[37m# software distributed under the License is distributed on an\u001b[39;49;00m\r\n",
      "\u001b[37m# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\u001b[39;49;00m\r\n",
      "\u001b[37m# KIND, either express or implied.  See the License for the\u001b[39;49;00m\r\n",
      "\u001b[37m# specific language governing permissions and limitations\u001b[39;49;00m\r\n",
      "\u001b[37m# under the License.\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# Network definition\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmodel_def\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Attention\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mIn model_fn. Model directory is -\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(model_dir)\r\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    model = Attention()\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoading the histopathology mil model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "        model.load_state_dict(torch.load(f, map_location=device))\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize code/inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "lrBb96KOEKT0"
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "model = PyTorchModel(model_data=model_data, source_dir='code',\n",
    "                        entry_point='inference.py', role=role, framework_version='1.6.0', py_version='py3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6u6HzY_lFTBv"
   },
   "source": [
    "#### Deploy the model on an endpoint\n",
    "You create a predictor by using the model.deploy function. You can optionally change both the instance count and instance type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "fmSumXLREaMV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m5.24xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOn7-dTgFW58"
   },
   "source": [
    "### Test the model\n",
    "You can test the depolyed model using samples from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_from_s3(bucket, key):\n",
    "    bucket = s3_resource.Bucket(bucket)\n",
    "    image = bucket.Object(key)\n",
    "    img_data = image.get().get('Body').read()\n",
    "\n",
    "    return Image.open(io.BytesIO(img_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TileDataset(data_utils.Dataset):\n",
    "\n",
    "    def __init__(self, img_path, folder_num, dataframe, num_tiles, transform=None):\n",
    "        \"\"\"\n",
    "        img_path: Where the images are stored\n",
    "        dataframe: The train.csv dataframe\n",
    "        num_tiles: How many tiles should the dataset return per sample\n",
    "        transform: The function to apply to the image. Usually dataaugmentation. Do not do normalization here.\n",
    "        \"\"\"\n",
    "        self.img_path = img_path\n",
    "        self.folder_num = folder_num\n",
    "        self.df = dataframe\n",
    "        self.num_tiles = num_tiles\n",
    "        self.img_list = list(self.df['image_id'])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_list[idx]\n",
    "\n",
    "        tiles = ['test_'+str(self.folder_num)+'/'+img_id + '_' + str(i) + '.png' for i in range(0, self.num_tiles)]\n",
    "        image_tiles = []\n",
    "        \n",
    "\n",
    "        for tile in tiles:\n",
    "            image = image_from_s3(self.img_path, tile)\n",
    "\n",
    "            if self.transform is not None:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            image = 1 - image\n",
    "            image = transforms.Normalize([1.0-0.90949707, 1.0-0.8188697, 1.0-0.87795304], [0.1279171 , 0.24528177, 0.16098117])(image)\n",
    "            image_tiles.append(image)\n",
    "\n",
    "        image_tiles = torch.stack(image_tiles, dim=0)\n",
    "\n",
    "        return torch.tensor(image_tiles), torch.tensor(self.df.iloc[idx]['isup_grade'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv(bucket, folder_num, df):\n",
    "    # Getting tiles that are in S3\n",
    "    print('Collecting list of tiles')\n",
    "    tiles_set = set()\n",
    "    bucket = s3_resource.Bucket('sagemaker-us-east-1-318322629142')\n",
    "    for key in bucket.objects.all():\n",
    "        if 'test_'+str(folder_num) in key.key:\n",
    "            tiles_set.add(key.key.split('/')[1].split('_')[0])\n",
    "    tiles_list = list(tiles_set)\n",
    "    \n",
    "    print('Creating dataframe')\n",
    "    # Creating dataframe containing labels for each tile in S3\n",
    "    tiles_df = pd.DataFrame(columns=['image_id', 'data_provider', 'isup_grade', 'gleason_score'])\n",
    "    for i in range(len(tiles_list)):\n",
    "        tiles_df = tiles_df.append(df.loc[df['image_id'] == tiles_list[i]])\n",
    "    \n",
    "    tiles_df = tiles_df.drop_duplicates()\n",
    "    return tiles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "cRjZBmrCFdfk",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting list of tiles\n",
      "Creating dataframe\n",
      "                              image_id data_provider isup_grade gleason_score\n",
      "1732  2b730c057bde4c56e79f693e3d577138       radboud          1           4+5\n",
      "1727  2b4d629c0b0a02ddfb05cc41c0c8dc65    karolinska          1           4+4\n",
      "1707  2ac5f9c41e6b9a004fc0cecf6c3083be    karolinska          0           3+3\n",
      "1774  2c8fd1d0ab8640342f6d10a0a54e5279    karolinska          0           0+0\n",
      "1254  1fc49bfab631583981f96f285ec0c94d    karolinska          1           4+5\n",
      "...                                ...           ...        ...           ...\n",
      "1709  2ad0f2857a4552a25127205fd04a5e9f       radboud          0           3+3\n",
      "1725  2b340c9844077ddcdf641adac5f116e3       radboud          0      negative\n",
      "1680  2a1c3373688904fcabbdeb4a177972f8       radboud          0           3+3\n",
      "1249  1fb65315d7ded63d688194863a1b123e    karolinska          1           5+5\n",
      "1257  1fe0cfea7347950a76bcbdafa0ad96ab    karolinska          0           3+4\n",
      "\n",
      "[125 rows x 4 columns]\n",
      "Creating data loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx =  0\n",
      "batch_idx =  1\n",
      "batch_idx =  2\n",
      "batch_idx =  3\n",
      "batch_idx =  4\n",
      "batch_idx =  5\n",
      "batch_idx =  6\n",
      "batch_idx =  7\n",
      "batch_idx =  8\n",
      "batch_idx =  9\n",
      "batch_idx =  10\n",
      "batch_idx =  11\n",
      "batch_idx =  12\n",
      "batch_idx =  13\n",
      "batch_idx =  14\n",
      "batch_idx =  15\n",
      "batch_idx =  16\n",
      "batch_idx =  17\n",
      "batch_idx =  18\n",
      "batch_idx =  19\n",
      "batch_idx =  20\n",
      "batch_idx =  21\n",
      "batch_idx =  22\n",
      "batch_idx =  23\n",
      "batch_idx =  24\n",
      "batch_idx =  25\n",
      "batch_idx =  26\n",
      "batch_idx =  27\n",
      "batch_idx =  28\n",
      "batch_idx =  29\n",
      "batch_idx =  30\n",
      "batch_idx =  31\n",
      "batch_idx =  32\n",
      "batch_idx =  33\n",
      "batch_idx =  34\n",
      "batch_idx =  35\n",
      "batch_idx =  36\n",
      "batch_idx =  37\n",
      "batch_idx =  38\n",
      "batch_idx =  39\n",
      "batch_idx =  40\n",
      "batch_idx =  41\n",
      "batch_idx =  42\n",
      "batch_idx =  43\n",
      "batch_idx =  44\n",
      "batch_idx =  45\n",
      "batch_idx =  46\n",
      "batch_idx =  47\n",
      "batch_idx =  48\n",
      "batch_idx =  49\n",
      "batch_idx =  50\n",
      "batch_idx =  51\n",
      "batch_idx =  52\n",
      "batch_idx =  53\n",
      "batch_idx =  54\n",
      "batch_idx =  55\n",
      "batch_idx =  56\n",
      "batch_idx =  57\n",
      "batch_idx =  58\n",
      "batch_idx =  59\n",
      "batch_idx =  60\n",
      "batch_idx =  61\n",
      "batch_idx =  62\n",
      "batch_idx =  63\n",
      "batch_idx =  64\n",
      "batch_idx =  65\n",
      "batch_idx =  66\n",
      "batch_idx =  67\n",
      "batch_idx =  68\n",
      "batch_idx =  69\n",
      "batch_idx =  70\n",
      "batch_idx =  71\n",
      "batch_idx =  72\n",
      "batch_idx =  73\n",
      "batch_idx =  74\n",
      "batch_idx =  75\n",
      "batch_idx =  76\n",
      "batch_idx =  77\n",
      "batch_idx =  78\n",
      "batch_idx =  79\n",
      "batch_idx =  80\n",
      "batch_idx =  81\n",
      "batch_idx =  82\n",
      "batch_idx =  83\n",
      "batch_idx =  84\n",
      "batch_idx =  85\n",
      "batch_idx =  86\n",
      "batch_idx =  87\n",
      "batch_idx =  88\n",
      "batch_idx =  89\n",
      "batch_idx =  90\n",
      "batch_idx =  91\n",
      "batch_idx =  92\n",
      "batch_idx =  93\n",
      "batch_idx =  94\n",
      "batch_idx =  95\n",
      "batch_idx =  96\n",
      "batch_idx =  97\n",
      "batch_idx =  98\n",
      "batch_idx =  99\n",
      "batch_idx =  100\n",
      "batch_idx =  101\n",
      "batch_idx =  102\n",
      "batch_idx =  103\n",
      "batch_idx =  104\n",
      "batch_idx =  105\n",
      "batch_idx =  106\n",
      "batch_idx =  107\n",
      "batch_idx =  108\n",
      "batch_idx =  109\n",
      "batch_idx =  110\n",
      "batch_idx =  111\n",
      "batch_idx =  112\n",
      "batch_idx =  113\n",
      "batch_idx =  114\n",
      "batch_idx =  115\n",
      "batch_idx =  116\n",
      "batch_idx =  117\n",
      "batch_idx =  118\n",
      "batch_idx =  119\n",
      "batch_idx =  120\n",
      "batch_idx =  121\n",
      "batch_idx =  122\n",
      "batch_idx =  123\n",
      "batch_idx =  124\n"
     ]
    }
   ],
   "source": [
    "bucket = 'sagemaker-us-east-1-318322629142'\n",
    "\n",
    "dataset_csv_key = 'panda_dataset.csv'\n",
    "dataset_csv_dir = 's3://{}/{}'.format(bucket, dataset_csv_key)\n",
    "df = pd.read_csv(dataset_csv_dir)\n",
    "\n",
    "df['isup_grade'] = df['isup_grade'].replace([1,2], 0)\n",
    "df['isup_grade'] = df['isup_grade'].replace([3,4,5], 1)\n",
    "\n",
    "test_df = get_csv(bucket, 1, df)\n",
    "print(test_df)\n",
    "\n",
    "transform_train = transforms.Compose([transforms.RandomHorizontalFlip(0.5),\n",
    "                                      transforms.RandomVerticalFlip(0.5),\n",
    "                                      transforms.ToTensor()])\n",
    "\n",
    "\n",
    "print('Creating data loader')\n",
    "test_set = TileDataset(bucket, 1, test_df, 16, transform=transform_train)\n",
    "\n",
    "batch_size = 1\n",
    "test_loader = data_utils.DataLoader(test_set, batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "for batch_idx, (data, label) in enumerate(test_loader):\n",
    "    print('batch_idx = ', batch_idx)\n",
    "    _, Y_hat, _ = predictor.predict(data)\n",
    "    predictions.append(int(Y_hat))\n",
    "    true_labels.append(int(label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.672\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqoA8ZlXFgqW"
   },
   "source": [
    "#### Cleanup\n",
    "If you don't intend on trying out inference or to do anything else with the endpoint, you should delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rY8U_J9HFiNy"
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "infer_pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
